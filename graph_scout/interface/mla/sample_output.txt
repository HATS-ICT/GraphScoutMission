Env created with configs: {'env_path': './', 'map_id': 'Std', 'max_step': 20, 'num_sub_step': 4, 'num_red': 2, 'num_blue': 2, 'health_red': 100, 'health_blue': 200, 'agents_init': {'R_0': {'type': 'RL', 'team_id': 0, 'direction': 2, 'posture': 0, 'node': 96, 'is_lr': True, 'is_ob': True}, 'R_1': {'type': 'RL', 'team_id': 0, 'direction': 2, 'posture': 0, 'node': 112, 'is_lr': True, 'is_ob': True}, 'B_0': {'type': 'DT', 'team_id': 1, 'direction': 1, 'posture': 0, 'path': [30, 31, 45, 46, 63, 68, 69, 86]}, 'B_1': {'type': 'DT', 'team_id': 1, 'direction': 4, 'posture': 0, 'path': [30, 31, 45, 46, 47, 48, 56, 72, 73, 74, 75, 84]}}, 'engage_range': {3: {'dist': 50, 'prob_add': 0.1, 'prob_mul': 1.0}, 2: {'dist': 150, 'prob_add': 0.05, 'prob_mul': 1.0}, 1: {'dist': 300, 'prob_add': 0.01, 'prob_mul': 1.0}}, 'engage_token': {0: 'none-visible', 1: 'far in sight', 2: 'yellow zone', 3: 'red zone', 4: 'overlap'}, 'sight_range': 0, 'damage_single': 10, 'damage_field': 3, 'field_boundary_node': 75, 'num_hibernate': 4, 'buffer_count': 4, 'branch_dict': {'num': [5, 3, 2, 0], 'bar': [0.2, 0.4, 0.6, 1.01]}, 'log_on': False, 'masked_act': True, 'penalty_invalid': 0, 'masked_obs': False, 'masked_map': False, 'has_sub_node': False}


#####===> Episode: 1 of 1


 Agent names (dictionary keys): ['R_0', 'R_1']
Init observations: [[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.3 0.  0.  0.  0.  0.3 0.3 0.3 0.3 0.3 0.  0.3 0.3 0.  0.3 0.3
  0.3 0.3 0.  0.  0.5 1.  0.3 0.3 0.3 0.2 0.  0.  0.5 0.5 0.  0.  0.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.5 0.5 0.5 0.3 0.1 0.1 0.1 0.1
  0.1 1.  0.5 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.5 0.5 0.5 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]
 [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.3 0.  0.  0.  0.  0.3 0.3 0.3 0.3 0.3 0.  0.3 0.3 0.  0.3 0.3
  0.3 0.3 0.  0.  0.5 1.  0.3 0.3 0.3 0.2 0.  0.  0.5 0.5 0.  0.  0.  0.
  0.  0.  0.  1.  0.  0.  0.  0.  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.5 0.5 0.5 0.3 0.1 0.1 0.1 0.1
  0.1 1.  0.5 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.5 0.5 0.5 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1
  0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.
  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]
###==> Step:1 of 20 | act:[[2, 1, 1], [4, 1, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:2 of 20 | act:[[2, 1, 1], [0, 2, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:3 of 20 | act:[[0, 2, 0], [2, 0, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:4 of 20 | act:[[4, 1, 1], [4, 3, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:5 of 20 | act:[[0, 0, 0], [0, 0, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:6 of 20 | act:[[3, 1, 0], [0, 1, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:7 of 20 | act:[[4, 0, 1], [4, 0, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:8 of 20 | act:[[2, 2, 0], [0, 0, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:9 of 20 | act:[[3, 3, 0], [2, 1, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:10 of 20 | act:[[3, 3, 0], [2, 3, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:11 of 20 | act:[[2, 1, 0], [4, 2, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:12 of 20 | act:[[1, 0, 0], [0, 0, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:13 of 20 | act:[[4, 0, 1], [4, 0, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:14 of 20 | act:[[4, 0, 1], [2, 3, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:15 of 20 | act:[[4, 3, 1], [4, 0, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:16 of 20 | act:[[4, 0, 0], [1, 2, 0]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:17 of 20 | act:[[1, 1, 0], [1, 3, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:18 of 20 | act:[[0, 3, 1], [4, 3, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:19 of 20 | act:[[1, 3, 0], [3, 2, 1]] rew:{'R_0': 0.0, 'R_1': 0.0}
###==> Step:20 of 20 | act:[[1, 2, 1], [0, 0, 1]] rew:{'R_0': 4.0, 'R_1': 4.0}
Agent_0: R_0 Node:[87, 3, 1] HP:76/100
Agent_1: R_1 Node:[57, 3, 1] HP:0/100
Agent_2: B_0 Node:[86, 2, 0] HP:80/200
Agent_3: B_1 Node:[84, 3, 0] HP:160/200
Rewards for all steps: [[4. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 3. 0. 0. 3. 1. 1. 0.]
 [4. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 3. 3. 1. 0. 0. 0. 0. 0. 0.]]
